\documentclass[final]{beamer}
\usepackage[size=a0]{beamerposter}
\mode<presentation>{\usetheme{lampinen}}
\usepackage{float}
\usepackage{url}           
%\usepackage{booktabs}      
\usepackage{amsfonts}      
\usepackage{bm}
%\usepackage{blkarray}
\usepackage{amssymb}
\usepackage{amsmath}
%\usepackage{nicefrac}      
%\usepackage{microtype}   
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{subcaption}
\usepackage[numbers]{natbib}
\usepackage{tikz}

\usetikzlibrary{shapes,arrows}

\tikzstyle{block} = [rectangle, draw, line width=2mm, align=center, rounded corners]
\tikzstyle{boundingbox} = [line width=2mm, lightgray]
\tikzstyle{dashblock} = [rectangle, draw, line width=2mm, align=center, dashed]
\tikzstyle{conc} = [ellipse, draw, thick, dashed, align=center]
\tikzstyle{netnode} = [circle, draw, line width=2mm, very thick, inner sep=0pt, minimum size=0.5cm]
\tikzstyle{relunode} = [rectangle, draw, very thick, inner sep=0pt, minimum size=0.5cm]
\tikzstyle{line} = [draw, line width=2mm, -latex']
\tikzstyle{arrow} = [draw, ->, line width=2mm]

\definecolor{bpurp}{HTML}{984ea3}
\definecolor{bblue}{HTML}{377eb8}


\setlength{\parskip}{0.5em}


% The \author macro works with any number of authors. There are two
% commands used to separate the names and addresses of multiple
% authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to
% break the lines. Using \AND forces a line break at that point. So,
% if LaTeX puts 3 of 4 authors names on the first line, and the last
% on the second line, try using \AND instead of \And before the third
% author name.

\title{Zero-Shot Task Adaptation by Homoiconic Meta-mapping (HoMM)}
\author{Andrew K. Lampinen \& James L. McClelland}
\institute{Department of Psychology, Stanford University}

\begin{document}

\begin{frame}[t]{}
\vspace{-1em}
\begin{columns}

\begin{column}[t]{0.248\textwidth}
\begin{block}{\huge Intro: zero-shot adaptation}
\vspace{-0.6em}
\begin{itemize}
\item Humans can adapt zero-shot to novel tasks, based on their relationship to prior tasks.
\item For example, if asked to alter our behavior on a game we have learned (like trying to lose or achieve some other goal), we can perform well on our first try.
\item We take inspiration from this to propose \emph{meta-mapping}, a novel function-transformation perspective on zero-shot task performance.
\item We propose Homoiconic Meta-Mapping (HoMM) architectures as a parsimonious implementation of this framework.
\item We demonstrate successful zero-shot adaptation to related but substantially different tasks, such as adapting to trying to lose a card game the system has been trained to win.
\end{itemize}
\end{block}
\begin{block}{\huge Meta-mapping}
\vspace{-0.6em}
\begin{itemize}
\item Consider a functional perspective. Basic tasks can be seen as functions mapping images to classes, or states to actions, or card hands to bets, etc.
\item We suggest it's then useful to think of transformations over functions, that is, functions which take other functions as input and/or output.
\item We call these higher-level functions \emph{meta-mappings}. They are functions which take basic functions as input and produce other basic functions as output.
\item For example, we could have a try-to-lose function which takes as input a function that tries to win money at poker, and outputs a function which tries to lose money at poker.
\item We suggest that meta-mappings are a useful way to think about human-like zero-shot adaptation.
\end{itemize}
\end{block}
\begin{block}{\huge Functional analogy}
\vspace{-0.6em}
\begin{itemize}
\item Meta-mappings can be learned in the same way that other functions are learned -- using a deep network to approximate the function.
\item We learn a meta-mapping from a dataset of example (input function, output function) tuples, analogously to learning a basic task from example tuples of (image, label), or (hand, bet, reward). 
\end{itemize}
\end{block}
\end{column}

\begin{column}[t]{0.496\textwidth}
\begin{block}{\huge Homoiconic Meta-Mapping (HoMM) architectures}
\vspace{-0.5em}
\begin{columns}
\begin{column}[t]{0.48\textwidth}
\textbf{Basic tasks (meta-learning):}
\begin{itemize}
\item We embed inputs and outputs into a shared latent space \(Z\). 
\item We meta-learn a network \(\mathcal{M}\) to map a dataset of embedded example tuples \(\{(z^{ex}_{in}, z^{ex}_{out}), ...\}\) to an embedding for that task/function \(z^{func}\). 
\item The function embedding \(z^{func}\) parameterizes a task-network \(F\), via a hyper network \(\mathcal{H}\).
\item The task network \(F\) transforms embedded inputs to results which are decoded to output.
\item The system is trained end-to-end.
\end{itemize}
\end{column}
\begin{column}[t]{0.48\textwidth}
\textbf{Meta-mappings (zero-shot task performance):}
\begin{itemize}
\item We exploit the analogy above to use \emph{the same meta-learning system} for meta-mappings.
\item We pass a dataset of example function mappings \(\{(z^{func}_{in}, z^{func}_{out}\}\) through \(\mathcal{M}\) to produce a meta-mapping embedding \(z^{meta}\). 
\item We parameterize \(F\) as before, and can pass a new function embedding through \(F\) to guess an embedding for a transformed task \(z^{func,pred}\).
\item We can use \(z^{func,pred}\) to perform a transformed task zero-shot (or train to match a target).
\item Parsimonious, same networks as basic meta-learning.
\end{itemize}
\end{column}
\end{columns}

\begin{figure}[H]
\centering
\normalsize
\begin{tikzpicture}[scale=2.5, every node/.style={scale=1}]
%% basic meta learning
\begin{scope}[shift={(0.4, 0.4)}]
\draw[boundingbox, fill=white] (-3, -4.3) rectangle (2.5, 3.2);
\end{scope}
\begin{scope}[shift={(0.2, 0.2)}]
\draw[boundingbox, fill=white] (-3, -4.3) rectangle (2.5, 3.2);
\end{scope}

\draw[boundingbox, fill=white] (-3, -4.3) rectangle (2.5, 3.2);
\node[lightgray] at (-1.2, 2.9) {(a) Basic meta-learning};
\node at (-1.5, -4) (examples) {Examples};
\node at (-1.5, -3.2) (D1) {
\(\left\{
\begin{matrix}
(z^{ex}_{in,0}, z^{ex}_{targ,0})\\
$\vdots$
\end{matrix}\right\}\)};

\node at (1.5, -4) (probes) {Probes};
\node at (1.5, -3.2) (D2) {
%\(z^{prb}_{in}\)};
\(\left\{
\begin{matrix}
z^{prb}_{in,0}\\
$\vdots$
\end{matrix}\right\}\)};

\node [block] at (-1.5, -1.95) (M) {\(\mathcal{M}\)};
\path [arrow] ([yshift=-5]D1.north) to (M);

\node at (-1, -1) (zfunc) {\(z^{func}\)};
\path [arrow, out=90, in=-135] (M.north) to ([xshift=5,yshift=2]zfunc.south west);

\node[block] at (0, -0.55) (H) {\(\mathcal{H}\)};
\path [arrow, out=45, in=180] ([yshift=-3]zfunc.north) to (H.west);

\node [block, dashed] at (1.5, -0.55) (F) {\(F_{z^{func}}\)};
\path[arrow] (H.east) to (F.west);

\path [arrow, dashed] (D2) to (F);

\node at (1.5, 1) (outputs) {
%\(z^{pred}_{out}\)};
\(\left\{
\begin{matrix}
z^{pred}_{out,0},\\
$\vdots$
\end{matrix}\right\}\)};
\node at (1.5, 1.75) (predictions) {Predictions};

\path [arrow, dashed] (F) to ([yshift=3]outputs.south);

\node at (-1.5, 1.75) (probetargs) {Probe targets};
\node at (-1.5, 1) (D2targs) {
%\(z^{prb}_{in}\)};
\(\left\{
\begin{matrix}
z^{prb}_{targ,0}\\
$\vdots$
\end{matrix}\right\}\)};

\node [align=center, text width=1.25 cm] at (0, 2.25) (dispatch) {\baselineskip=12pt Loss\par};

\path [arrow, dashed, out=180, in=-90] ([xshift=3]outputs.west) to (dispatch.south);

\path [arrow, dashed, out=0, in=-90] ([xshift=-3.5]D2targs.east) to (dispatch.south);



%% meta mapping
\begin{scope}[shift={(6.4, 1.5)}]
\draw[boundingbox, draw=bpurp, fill=white] (-3, -4.3) rectangle (2.6, 3.2);
\node[bpurp] at (-1.6, 2.9) {(b) Meta-mapping};
\node at (-1.5, -4) (metaexamples) {Examples};
\node at (-1.5, -3.2) (metaD1) {
\(\left\{
\begin{matrix}
(z^{func}_{in,0}, z^{func}_{targ,0})\\
$\vdots$
\end{matrix}\right\}\)};

\node at (1.5, -4) (metaprobes) {Probes};
\node at (1.5, -3.2) (metaD2) {
%\(z^{prb}_{in}\)};
\(\left\{
\begin{matrix}
z^{func,prb}_{in,0}\\
$\vdots$
\end{matrix}\right\}\)};

\node [block] at (-1.5, -1.95) (metaM) {\(\mathcal{M}\)};
\path [arrow] ([yshift=-5]metaD1.north) to (metaM);

\node at (-1, -1) (metazfunc) {\(z^{meta}\)};
\path [arrow, out=90, in=-135] (metaM.north) to ([xshift=5,yshift=2]metazfunc.south west);

\node[block] at (0, -0.55) (metaH) {\(\mathcal{H}\)};
\path [arrow, out=45, in=180] ([yshift=-3]metazfunc.north) to (metaH.west);

\node [block, dashed] at (1.5, -0.55) (metaF) {\(F_{z^{meta}}\)};
\path[arrow] (metaH.east) to (metaF.west);

\path [arrow, dashed] (metaD2) to (metaF);

\node at (1.5, 1) (metaoutputs) {
%\(z^{pred}_{out}\)};
\(\left\{
\begin{matrix}
z^{func,pred}_{out,0},\\
$\vdots$
\end{matrix}\right\}\)};
\node at (1.5, 1.75) (metapredictions) {Predictions};

\path [arrow, dashed] (metaF) to ([yshift=3]metaoutputs.south);

\node at (-1.5, 1.75) (metaprobetargs) {Probe targets};
\node at (-1.5, 1) (metaD2targs) {
%\(z^{prb}_{in}\)};
\(\left\{
\begin{matrix}
z^{func,prb}_{targ,0}\\
$\vdots$
\end{matrix}\right\}\)};

\node [align=center] at (0, 2.25) (metadispatch) {Loss (train)};

\path [arrow, dashed, out=180, in=-90] ([xshift=3]metaoutputs.west) to (metadispatch.south);

\path [arrow, dashed, out=0, in=-90] ([xshift=1]metaD2targs.east) to (metadispatch.south);


\end{scope}
\path [arrow, line width=2mm, draw=bpurp, dotted, out=-40, in=-140] ([xshift=-1, yshift=3]zfunc.south) to ([xshift=17, yshift=2]metaD1.west);

%% evaluating meta mapping
\begin{scope}[shift={(12.1, 0)}]
\draw[boundingbox, draw=bblue, fill=white] (-2.65, -4.3) rectangle (2.85, 3.2);
\node[bblue] at (-0.85, 2.85) {(c) Zero-shot evaluation};

\node at (1.5, -4) (metaevalprobes) {Probes};
\node at (1.5, -3.2) (metaevalD2) {
%\(z^{prb}_{in}\)};
\(\left\{
\begin{matrix}
z^{prb}_{in,0}\\
$\vdots$
\end{matrix}\right\}\)};

\node at (-1, -1) (metaevalzfunc) {\(z^{func,pred}\)};

\node[block] at (0, -0.55) (metaevalH) {\(\mathcal{H}\)};
\path [arrow, out=45, in=180] ([yshift=-3]metaevalzfunc.north) to (metaevalH.west);

\node [block, dashed] at (1.5, -0.55) (metaevalF) {\(F_{z^{func,pred}}\)};
\path[arrow] (metaevalH.east) to (metaevalF.west);

\path [arrow, dashed] (metaevalD2) to (metaevalF);

\node at (1.5, 1) (metaevaloutputs) {
%\(z^{pred}_{out}\)};
\(\left\{
\begin{matrix}
z^{pred}_{out,0},\\
$\vdots$
\end{matrix}\right\}\)};
\node at (1.5, 1.75) (metaevalpredictions) {Predictions};

\path [arrow, dashed] (metaevalF) to ([yshift=3]metaevaloutputs.south);

\node at (-1, 1.75) (metaevalprobetargs) {Probe targets};
\node at (-1, 1) (metaevalD2targs) {
%\(z^{prb}_{in}\)};
\(\left\{
\begin{matrix}
z^{prb}_{targ,0}\\
$\vdots$
\end{matrix}\right\}\)};

\node [align=center] at (0.3, 2.25) (metaevaldispatch) {Loss (eval)};

\path [arrow, dashed, out=180, in=-90] ([xshift=3]metaevaloutputs.west) to (metaevaldispatch.south);

\path [arrow, dashed, out=0, in=-90] ([xshift=-0.5]metaevalD2targs.east) to (metaevaldispatch.south);
\end{scope}
\path [arrow, line width=2mm, draw=bblue, dotted, out=-30, in=160] ([xshift=3,yshift=-3]metaoutputs.center) to ([xshift=2, yshift=-10]metaevalzfunc.north west);
\end{tikzpicture}
%\caption{The HoMM architecture allows for transformations at different levels of abstraction. (a) For basic meta-learning a dataset consisting of (input embedding, output embedding) tuples is processed by the meta-network \(\mathcal{M}\) to produce a function embedding \(z^{func}\), which is processed by the hyper network \(\mathcal{H}\) to parameterize a function \(F_{z^{func}}\), which attempts to compute the transformation on probe inputs (used to encourage the system to generalize). However, our approach goes beyond basic meta-learning. The function embedding \(z^{func}\) can then be seen as a single input or output at the next level of abstraction, when the same networks \(\mathcal{M}\) and \(\mathcal{H}\) are used to transform function embeddings based on examples of a meta-mapping (b). To evaluate meta-mapping performance, a probe embedding of a held-out function is transformed by the architecture to yield a predicted embedding for the transformed task. The performance of this predicted embedding is evaluated by moving back down a level of abstraction and evaluating on the actual target task (c). Because the function embedding is predicted by a transformation rather than from examples, new tasks can be performed zero-shot. (\(M\) and \(H\) are learnable deep networks, and $F_{z}$ is a deep network parameterized by $\mathcal{H}$ conditioned on function embedding \(z\). Input and output encoders/decoders are omitted for simplicity. See the text and Appendix \ref{app_model_details} for details.)} \label{architecture_inference_fig}
\end{figure}
\end{block}

\begin{block}{\huge Experiments}
\vspace{-0.5em}
\begin{columns}
\begin{column}[t]{0.48\textwidth}
\textbf{Polynomial regression:}
\begin{itemize}
\item Basic tasks: regress polynomials (degree \(\leq 3\)) in 4 variables from examples. 
\item Meta-mappings: transform polynomial by permuting variables, adding or multiplying constants, squaring. 
\item Good zero-shot performance!
\end{itemize}
\begin{figure}[H]
\includegraphics[width=0.7\textwidth]{../figures/poly/meta_results.png}
\end{figure}
\end{column}
\begin{column}[t]{0.48\textwidth}
\textbf{Simple card games:}
\begin{itemize}
\item Basic tasks: input is hand, make bet, get stochastic reward. A variety of games with different rules. 
\item Meta-mappings: transform game by trying to lose, changing values of suits. 
\item Good zero-shot performance!
\end{itemize}
\begin{figure}[H]
\includegraphics[width=0.7\textwidth]{../figures/meta_mapping.png}
\end{figure}
\end{column}
\end{columns}
\end{block}
\end{column}


\begin{column}[t]{0.248\textwidth}
\begin{block}{\huge Why \& prior work}
\begin{itemize}
\item Prior work has considered zero-shot task performance from language descriptions, with approaches that implicitly use prior task knowlege for the novel task.
\item However, transforming a task representation provides a richer and more explicit way to use prior knowledge.
\item Probably because of this, meta-mapping offers better zero-shot performance than a baseline of performing the task from natural language alone.
\item Meta-mapping thus offers a happy intermediate between meta-learning (which requires data on the new task), and zero-shot performance from language alone.
\end{itemize}
\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{../figures/why_meta_mapping.png}
\label{fig_why_meta_mapping}
\end{figure}

\end{block}
\begin{block}{\huge Conclusions}
\end{block}
\end{column}
\end{columns}
\end{frame}
\end{document}
