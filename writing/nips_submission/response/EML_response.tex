\documentclass{article}

\usepackage{neurips_2019_author_response}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm}

\usepackage{wrapfig}

\usepackage{tikz}

\usetikzlibrary{shapes,arrows}

\tikzstyle{block} = [rectangle, draw, thick, align=center, rounded corners]
\tikzstyle{boundingbox} = [very thick, dotted, gray]
\tikzstyle{dashblock} = [rectangle, draw, thick, align=center, dashed]
\tikzstyle{conc} = [ellipse, draw, thick, dashed, align=center]
\tikzstyle{netnode} = [circle, draw, very thick, inner sep=0pt, minimum size=0.5cm]
\tikzstyle{relunode} = [rectangle, draw, very thick, inner sep=0pt, minimum size=0.5cm]
\tikzstyle{line} = [draw, very thick, -latex']
\tikzstyle{arrow} = [draw, ->, very thick]

\begin{document}
\begin{wrapfigure}{r}{0.27\textwidth}
\begin{center}
\begin{tikzpicture}[auto, scale=0.75]
\node at (-1.5, -3.5) (examples) {Examples};
\node at (-1.5, -2.5) (D1) {
\(\left\{
\begin{matrix}
(z^{ex}_{in,0}, z^{ex}_{targ,0})\\
$\vdots$
\end{matrix}\right\}\)};

\node at (1.5, -3.5) (examples) {Probes};
\node at (1.5, -2.5) (D2) {
%\(z^{prb}_{in}\)};
\(\left\{
\begin{matrix}
z^{prb}_{in,0}\\
$\vdots$
\end{matrix}\right\}\)};

\node at (-0.33, -0.66) (zfunc) {\(z^{func}\)};

\path [arrow] (D1) to [in=-145, out=90] ([xshift=3, yshift=3]zfunc.south west) node [xshift=-16, yshift=-5] {\(\mathcal{M}\)};

\node at (1.5, -0.25) (F) {\(F\)};

\path [arrow, bend left] ([xshift=-5, yshift=-5]zfunc.north east) to [in=165, out=25] ([xshift=3]F.west) node [xshift=-13, yshift=5]{\(\mathcal{H}\)};

\path [arrow, dashed] (D2) to (F);

\node at (1.5, 1.75) (outputs) {
%\(z^{pred}_{out}\)};
\(\left\{
\begin{matrix}
z^{pred}_{out,0},\\
$\vdots$
\end{matrix}\right\}\)};
\node at (1.5, 2.8) (predictions) {Predictions};

\path [arrow, dashed] (F) to ([yshift=3]outputs.south);

\node [align=center, text width=1.25 cm] at (-1.5, 1.75) (dispatch) {Loss or eval or ...};

\path [arrow, dashed] (outputs.west) to ([xshift=-3]dispatch.east);
\end{tikzpicture}
\end{center}
\vspace{-1.5em}
\end{wrapfigure}
\looseness=-1
We thank the reviewers for their thoughtful and thorough reviews. \par
\looseness=-1
\textbf{Architecture \& contributions:} We agree with the reviewers that the most novel contribution of our paper is the proposal to think about transfer in terms of meta-mappings and task transformations. We would like to clarify how the architecture functions and how it is novel. To begin, we will clarify how a basic polynomial like $x + 1$ is learned. This is depicted schematically in the figure. As in standard meta-learning, we generate a set of examples, consisting of tuples of input point, and the target output (i.e. the polynomial value) at each point. The meta-network $\mathcal{M}$ processes this set of (embedded input, embedded target) pairs to produce a function embedding. Specifically, it concatenates each pair, applies two layers of identical processing to each concatenated pair independently, then max pools elementwise across them, and then applies two more layers of processing to produce the function embedding which represents this polynomial. This procedure is permutation invariant by design. We then pass the function embedding $z^{func}$ through the hyper network $\mathcal{H}$ to parameterize a function $F$ which ideally performs the mapping from inputs to outputs. We can then take a new set of probe inputs (i.e. points we want to evaluate the polynomial at), transform them according to $F$ to produce a set of predictions, and then train the model or evaluate it if we have targets. As the reviewers noted, this is similar to many existing meta-learning approaches. \par 
\looseness=-1
\textbf{The insight of our paper is that meta-mappings over polynomials are exactly analogous to basic meta-learning of a polynomial.} Instead of having examples of inputs and outputs for a single polynomial, we have examples of input polynomials and output polynomials for a more abstract function that operates over polynomials (e.g. multiplying by 2). These polynomials are embedded as above, by passing examples of them through the meta network to compute a function embedding. We then can take these pairs of (embedded input polynomial, embedded target polynomial), and pass them through the \textbf{exact same meta network} $\mathcal{M}$ to produce an embedding for this meta-task. Just as above, we can pass this function embedding through the same hyper network $\mathcal{H}$ to parameterize a function $F$ which attempts to multiply polynomials by 2. We can then pass a probe polynomial through $F$ to produce a predicted output. The only differences from the basic case are 1) where the inputs and targets come from and 2) how the loss or evaluation is computed from the predictions. For basic training, we used an appropriate loss in the output space for each task, in meta training, we used an $\ell^2$ between the predicted task embedding, and the embedding of the target task. To evaluate the real performance on a meta-mapping, we actually computed the performance of the predicted output embedding at regressing the target polynomial. For example, if the meta-mapping was ``multiply by 2'' and the probe input was $x + 2$, we would evaluate how closely the predicted output polynomial matched $2x + 4$ by feeding the predicted function embedding to the hyper network to parameterize a function, feeding inputs to this function, and then measuring its predicted outputs. We hope this clarifies how our architecture works, and why it is fundamentally different from prior work. All three reviewers highlighted the novelty of considering transformations over tasks. That is the conceptual contribution of our paper, but the architectural contribution of our paper is to show a way that meta-mappings can be parsimoniously integrated into a meta-learning architecture without adding a single parameter. We show in Appendix D.1 that this actually performs better than having separate meta and hyper networks for basic tasks and meta-mappings. These conceptual and architectural contributions are the main points of the paper, natural language and continual learning are side points. (We are revising the main text to clarify this.) \par 
\looseness=-1
\textbf{Architecture:} The reviewers noted that some of the architectural choices seemed arbitrary. We justify some choices in appendix D, but we acknowledge that we have not explored the full space of approaches to this problem, and we see alternatives as an exciting future direction. Our work proposes the challenge of meta-mappings, and a starting point for thinking about the solutions. A note on the DQN: the problem as we have defined it is not exactly a standard supervised problem because you only observe the reward for the action you execute, but we are not using a full DQN. \par 
%\textbf{Relation to other work:} We do think that combining other meta-learning approaches such as MAML with a system like ours is an interesting direction for future work. \par 
%\looseness=-1
%\textbf{Contributions:} As all three reviewers noted, the most novel contribution of our paper is the proposal to think about transfer in terms of meta-mappings and task transformations. The architecture we propose is designed with this idea in mind. It is true that previous work has considered task embeddings (some of the works suggested by the reviewers we have mentioned in the related works section, but some we were not familiar with, we appreciate the pointers). Most of this work has developed some way of embedding a task or dataset into some latent space. However, what we think is fundamentally novel about our architecture is that \textbf{we use the same latent space for the dataset as we use for an individual input to the network}. This allows us to use the same meta and hyper networks for both basic tasks and meta-mappings. We show in appendix D.1 that this performs better than separate embedding spaces. We think that this is a fundamentally novel aspect of our architecture, since it is primarily useful for the meta-mappings we propose. While other techniques that create explicit task embeddings could also be trained to transform them for meta-mappings, we think our novel insight of a shared embedding space for individual data points and tasks would result in better performance with other algorithms too. We do think that combining other meta-learning approaches such as MAML with a system like ours is an interesting direction for future work. As we point out in the future directions, we do not expect the exact approach we've proposed to be the best way of solving these problems. However, it does provide a useful starting point. We think that the primary contribution of this work is highlighting the idea of meta-mappings for transfer, and providing some starting points for how to approach them by taking a functional perspective, which we hope will inspire future work. \par
%\looseness=-1
%\textbf{Meta-mapping details:} For a concrete training example, imagine trying to map from winning tasks to losing them. Suppose we have three tasks, chess, poker, and go, and losing variations of each. We generate task embeddings for each game, e.g. $z_{poker}$, by applying the meta network $\mathcal{M}$ to experiences from the game. We randomly select some games (poker, go) to use as training examples to generate the meta-mapping parameters, and hold-out the rest (chess) to make the generated meta-mapping generalize. We thus generate a dataset $D = {(z_{poker}, z_{lose-poker}), (z_{go}, z_{lose-go})}$. Per above, we process this dataset using the same meta-network $\mathcal{M}$ to get a function embedding $z_{lose} = \mathcal{M}(D)$ for the meta-mapping. We can then pass this embedding through the hypernetwork $\mathcal{H}$ in order to parameterize a mapping $F_{z_lose}$ which attempts to map game strategies to strategies for the losing variation of that game. We use this mapping to transform each input embedding and compute the $\ell_2$ loss between the result and the target function embedding, e.g. for chess the loss would be $(F_{z_lose}(z_{chess}) - z_{lose-chess})^2$. We minimize this loss across all held-out and training examples (using both accelerates learning). We then proceed with the next meta-mapping. \par
%\looseness=-1
%To evaluate performance on a meta-mapping, we generate the training dataset as above, but we do not assume we have an embedding for the held-out targets. For example, we may know how to play chess via a task embedding $z_{chess}$, but our goal is to figure how to lose at chess. So we take $\hat{z}_{lose-chess} = F_{z_{lose}}(z_{chess})$, and use it to play losing chess by parameterizing a function $F_{\hat{z}_{lose-chess}}$. We then evaluate this function's actual performance on losing chess, which tells us the true quality of the meta-mapping. We hope this clarifies the training and evaluation of meta-mappings. We have revised the manuscript to be more explicit about this and fix typos noted by reviewer 1, and if our manuscript is accepted we will also incorporate more details of tasks and training from the appendix as space allows. \par
\looseness=-1
\textbf{miniImageNet:} TBD. \par
\looseness=-1
\textbf{Datasets:} The polynomials and cards tasks are implemented as stand-alone python modules that other researchers can use, and will be released on github. Creating complex datasets for meta-mappings is an important future direction. \par
\looseness=-1
\textbf{Natural language:} Language was simply used as a meta-mapping cue in the main text (but c.f. appendix A). Specifically, we used the language embedding as input to the hyper network to generate the meta-mapping parameters. \par
\looseness=-1
\textbf{Continual learning:} Any architecture which generates task embeddings could cache them, but we have not seen prior work suggest this. This approach does requires storing an embedding vector per task, but many other approaches (such as EWC) require storing an extra ``importance'' parameter for each model parameter. For modern models with up to billions of parameters, caching a relatively low-dimensional embedding per task would consume less memory than doubling the parameter count, even up to millions of tasks. We think this observation is somewhat interesting, but it is not the main point of our article, so we have slightly de-emphasized it in the main text. \par
\end{document}
